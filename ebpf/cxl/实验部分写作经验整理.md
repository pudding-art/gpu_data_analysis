# 实验部分写作经验整理

C类论文更多关注创新点，B类论文更多关注细节和工作量。把创新的地方说清楚。

整体的思路是：实验->针对实验的技术路线/实现->系统架构（前端需要哪些接口，物理条件，研究对象）->解决一个什么问题（问题创新：新技术解决旧问题，还是旧技术解决新问题）。**比如软件方面的缓存放到了CXL Memory上要比用软件好，从模型适配的角度来说。**

问题-挑战-动机：挑战是问题的难度，难点部分

Fig1 最好放在第一页的右上角，用图来反馈work motivation，”以前->现在“, 主要是动机图，绘制其他的background的图也可以。

Fig2 Host Hardware部分可不可以加一个网络设备Network模块，因为后面涉及到memory pool是一定需要网络支持的，即使现在没有实现，也可以写上先把坑占上？然后相关的部分放到Discussion部分说明？如果是多主机上都可以运行gem5构成网络，Host OS（可以是各种OS或者是虚拟机以及容器）可以画2个或者多个。

However后的信息一定要好好写，很重要很重要，往往反映着现象、动机和方法。

为什么当前的实验中没有和QEMU对比的东西，到底是上下级的关系还是并行的关系，2种不同的东西。QEMU是内核级，Gem5是用户级，不需要对比，这样反而就不需要加QEMU的内容，但是在论文中要说明白，封死了，别让人找出破绽。

在框架图和结构图中，将自己的工作用有颜色的框图表示；前面图像的颜色还要还，一样的地方颜色和形状要统一，有问题的地方不要放在一起，不是一件事就分开，比如现在的图Bridge和左边的Memory Alloctor以及HDM Driver有啥关系？不要让人怀疑

App的应用中要标注如何使用这个应用（应该不用修改了，就是App Managed和Kernel Managed的管理方式；

gem5架构图中，黑白的interface是什么方向要说明；MemBus和IOBus的线是空间关系还是时间关系？空间关系就是不同的时间剖面都一致；数据packet有不同，要有封帧的过程，哪一步有原始数据的封装。

读写数据流中，读和写有没有冲突（防止人问，有什么解决方案吗？），可以在contribution list中加上读写控制机制的实现。**==读写控制机制和Packet格式的转变可以单独再写一篇论文。==**



#### Contribution

这部分也要改，前面1已经说了Gem5,后面2还说Gem5就很重复，不要重复说，有凑数/模糊的问题。

这部分能多写就多些，多多益善。



#### 实验配置部分：

- 一段超过十句就要分成两段说；
- 要有逻辑性，可以先讲硬件->软件, 也可以按照前面架构图的顺序来讲或者也可以是其他合理的逻辑顺序；
- 由于CXL-MemSim， remote NUMA, and CXL prototype都是在现在的这个硬件上实现的，所以其实可以先说这个硬件系统，然后分别说remote NUMA， CXL真实设备的配置，最后再说CXL-MemSim的配置；
- 板卡不要说一个，要说一套；

#### 实验评估部分：

- [x] 参考其他模拟器的文章实验部分是怎么写的，比如SimpleSSD，思路扩展一下
- [ ] 扩展性/不灵活放到那个方面，硬件配置，介质不灵活, motivation要说，这个工作没做也要写，这样其他人的工作就绕不开你了，把后面能想到的问题都写在里面。
- [x] YCSB的负载也要说一下，如果是不同模拟或者不同算法设计的工作，一定要有可比性，workload不同的话，要讲一下workload哪里不同，比如内部的读写比例不同，文字中要描述一下不同的工作负载，以及负载存在的必要性，比如这里为什么一定要用6种工作负载而不是只用其中的一种，要给出理由；
- [ ] Redis的图像，不同比例但是具体的介质相同的用一个颜色就行了，现在的维度太多了比较乱，颜色和网格都有（负载的重构）；
- [x] 使用每种工具进行测试时，具体对测试工具的介绍要放到第二句来讲，先写要测xxx延迟以及为什么要测xxx的延迟，先从大的方面说要测什么、干什么；实验使用的benchmark和器材当成是自己的，不需要给别人科普lmbench这些测试程序是什么以及为什么要做这件事，这些都应该在related work中阐述；
- [x] 整体的测试区分种类中间那个advantages要改一下，改成可靠性或敏感性之类的，要和其他两种保持一致。sensitity rebility等，the advantages of感觉不是一个层次；
- [x] 所有的测试的“Tests"都去掉，中式英语；
- [x] 注意scale, expand, extend是不一样的，扩展和拓展是不一样的；介质的替换也是一种扩展，也可以看成是异构；
- [x] 还有Avaliablity测试中前面是Latency, Bandwidth后面突然是Real-world Database Test感觉很突兀，应该选择一个同样表达抽象概念的词汇，比如改成throughput或者QPS；
- [ ] MERCI QPS的实验结果比较单调，把其他的都补充一下；
- [x] 几个配图的文字描述部分都需要修改，现在看着像是只描述前提，具体干啥了，干了啥事儿都没说清楚；配图的文字解释要统一风格；比如你起的是STREAM bandwidth，看起来是要测STREAM的带宽，而不是为CXL-MemSim服务，注意自己要表达的是什么；
- [x] 描述实验的时候，先说要测内存，然后将对应的benchmark比如STREAM等针对我现在的比测带宽的事情，而不是STREAM要求的东西，**而是我自己要做的东西，不要科普STREAM，而是STREAM在我的实验中是怎么回事，先说自己的我们从xxx角度去测试自己的工作**（我正好需要->STRAEM正好有）。写大论文也是这样，要把别人的变成自己的；
- [x] 每段都要按照总分总的格式描述，最后都要加一句总结的描述上面的现象；
- [x] 关于一些array size设置的问题，最好是通过一组实验得出一组实验最好，最后再说选这个数，”从实验得到的xxx”，要说明是经验值还是什么，如果参考了其他的工作中的设置，要加参考文献；
- [x] 实验评估的第一句话说整体的总的结果，不要啰嗦，也可以说横纵坐标，针对不同硬件的结果
- [ ] load有2种方式：复制方式（用复制到内存吗？），内存定位（取的是数据还是地址？），无论是什么，原因都要说全了，比如直接存取要说很多细节；
- [x] 为什么使用Viper和Redis两款App，都有什么理由，不要去讲自己改了Viper，不要激起审稿人的逆反心理想要怼你，直接说这是一个benchmark就行；
- [x] 在实验部分证明自己比别人好同时也要说明为什么比别人好；

### Discussion部分：

- 想做但是没做的，写点不痛不痒的内容，不写也行，看下要投的期刊或会议的要求，让写的时候再写，否则给他人留机会；
- 比如有些数据需要测一万次，但是只测了一百次下一步想要丰富测试的数据量，写一些别人没有条件去做的事情，在真实的Data Center中做能达到多少，给别人设个门槛，知道有这方面的工作，但是做不了；

### Conclusion：

- 通过xx实验得到了一些数据，具体展示了哪些方面，结论不一定是一个，什么样的负载、数据才有这样的结果，如果放在abstract中通过xx实验得到xx结果（和结论中不同）



**“适应性”或“灵活性”**

“适应性”强调了系统或架构在更换介质后能够适应新的存储或性能需求的能力。它表明系统具有良好的**兼容性**和**可调整性**，能够根据不同的应用场景灵活调整其配置。

“灵活性”则突出了系统或架构在介质更换方面的灵活性和可变性。它意味着系统能够轻松地进行介质升级或替换，以满足不断变化的存储和性能需求。

adaptability

compatibility

flexibility



### 待完成工作

1. MERCI的图像问题：

MERCI的数据少，看起来有些空，把图横过来画可能会好一些

2. Viper容量受限的场景：

（1）用mem-emu尝试划分分配比例，这个可以用prefered策略

（2）如果用numactl没法用prefer策略（也不一定，也可以试试，通过改swampiness)，如果用interleave策略会有潜在的带宽增加的优势

（3）和gem5完全相同的数据是不可能了，但是可以类似的配比，但是在描述的时候应该如何去描述这件事情呢？

3. Discussion和Conclusion的思路问题（ok）



#### Contribution List:

里面的内容还需要加强，具体的观点划分要仔细。

### Discussion：

想做但是没做的or正在进行中：

1. 涉及到多节点的内存池模拟，主要是CXL2.0的池化场景模拟，Switch的模拟；
2. CXL Type2 Device的模拟；
3. CXL协议本身没有定义后端设备的具体配置，因此后端设备的容量、介质、通道数都可以不同，这方面的工作也在进行中（表明CXL-MemSim具有良好的兼容性和可调整性，能够根据不同的应用场景灵活调整配置）；

不痛不痒的：

1. 以上实验证明Kernel Managed mode和App Managed mode均可用，但是由于篇幅限制，App Managed实验仅做了一个；
2. 寻找更多的CXL memory的应用场景；

### Conclusion:



~~This paper presents CXL-MemSim, a novel full-system simulator for CXL disaggregated memory systems, developed upon the gem5 platform. Our key contributions include:~~

~~Innovative Simulation Framework: The introduction of CXL-MemSim, enabling the study of CXL memory systems through a detailed simulation approach.~~

Hardware-Software Co-Design: Design and implementation of a CXL memory device model and its corresponding driver, facilitating a comprehensive analysis of CXL memory protocols.

Performance Evaluation: An extensive benchmarking suite demonstrating CXL-MemSim's ability to accurately reflect the latency and bandwidth of CXL memory systems.

Application-Level Assessment: Insights into the impact of CXL memory on real-world applications, highlighting the nuanced performance effects of heterogeneous memory policies. 

**Future Directions:** While CXL-MemSim significantly advances CXL memory system simulation, future work will focus on enhancing the simulator's capabilities to include a broader range of memory technologies and access patterns. 

Additionally, we aim to integrate emerging CXL features and standards as they become available, ensuring CXL-MemSim remains at the forefront of CXL research and development.

 **Limitations:** The study's limitations lie in the inherent constraints of simulation-based research, which may not fully encapsulate the complexities of real-world hardware interactions. However, CXL-MemSim provides a solid foundation for further exploration into the potential and optimization of CXL-based systems.



In this paper, we present CXL-MemSim, a novel full-system simulator for CXL disaggregated memory systems~~, developed on the gem5~~. **The introduction of CXL-MemSim, enabling the study of CXL memory systems through a detailed simulation approach.** ~~We design and implement a CXL memory expander and its corresponding driver, facilitating support for CXL sub-protocols(CXL.io and CXL.mem).~~ ~~An extensive benchmarking suite demonstrating CXL-MemSim has ability to accurately reflect the latency and bandwidth of real CXL memory,  and it can be used in real-world applications highlighting the nuanced performance effects of heterogeneous memory policies.~~  ~~Our analysis also identified opportunities to effectively use CXL memory as a memory bandwidth expander for memory-bandwidth-intensive applications. We use CXL memory as a memory capacity expander for memory-capacity-intensive applications.~~ Finally, we evaluate the scalalibility of CXL-MemSim, CXL-MemSim can simulate various CXL memory devices integrated with different storage medium, providing a broad exploration and design space for the research of future heterogeneous memory-pooled systems.

Future Direction:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 We aim to integrate CXL.cache and CXL type 2 device to our simulator. Future work will focus on enhancing the simulator's capabilities to include a broader range of memory technologies and access patterns. To ensue CXL-MemSim remains at the forefront of CXL research and development.

Limitations: The variation can attributed to the fact that the  X86O3CPU model we used on CXL-MemSim cannot absolutely match today's advanced Xeon CPU.  However, CXL-MemSim provides a solid foundation for further exploration into the potential and optimization of CXL-based systems.



 

~~In this paper we present a CXL disaggregated memory simulator based on gem5.~~ ~~First, we create a CXL type 3 device with memory capability and CXL protocol processing. The driver is developed at kernel level. We provide two methods for using the CXL memory.~~ ~~Finally, we evaluate the performance of the system. The HDM latency in our implementation is about 1.5 times that of DRAM, while the bandwidth is about 70\% to 80\% of DRAM. We conducted a study using the Redis application on both DRAM and HDM. Our results show that simply using heterogeneous memory does not improve application performance. We believe that our work will provide a basis for CXL simulation in gem5.~~



结尾部分思路：

1. design；

   In this paper, we present CXL-MemSim, a novel full-system simulator for CXL disaggregated memory systems. CXL-MemSim implements a CXL memory expander and its corresponding driver are implemented, providing support for CXL sub-protocols (CXL.io and CXL.mem). 

2. 实验评估结果（模拟器可以模拟真实的设备特性和性能；探索CXL内存的优势，容量扩展和带宽扩展；scalability部分）；

   - Comprehensive benchmarks demonstrate CXL-MemSim can accurately reflect the latency and bandwidth of real CXL memory. 

   - In addition, it can be used in real-world applications to illustrate the complex impact of heterogeneous memory policies on performance.
   - We found that CXL memory could expand capacity where local memory is limited and boost bandwidth for memory-bandwidth-intensive applications.
   - CXL-MemSim scales across diverse storage mediums, providing a wide design space for future memory disaggregated systems. 

3. remote NUMA不能很好的模拟真实CXL设备的特性；

   - Our experiments also exposed key performance variances between emulated and real CXL memory.

4. limitation（CXL-MemSim中的CPU模型无法完全match当前的Xeon CPU性能, 也可以不写）；

   - The CPU model within CXL-MemSim does not fully match the performance of current Xeon CPUs.

5. future work（CXL.cache及type2设备；集成其他存储介质；分析性能数据进行更广泛的研究，如结合深度学习等）；

   - In the future, we aim to integrate CXL.cache and CXL type 2 device to our simulator. In addtion, we will continue to enhance the capabilities of CXL-MemSim to provide a solid foundation for further exploration into the potential and optimization of CXL disaggregated memory systems.

6. CXL-MemSim provides a solid foundation for further exploration into the potential and optimization of CXL disaggregated memory systems.  

7. Thus it enables researchers to study diverse system performance characteristics from a holistic viewpoint.





In the future, we can continue to explore memory pooling scenarios in memory disaggregation based on the current approach. In addition, we will continue to optimize the access latency with cache prefetching and hard CXL IP on FPGA. We will test more real workloads, e.g. latency-sensitive and latencyinsensitive use cases, and believe our approach is competitive in many scenarios in data centers.



With CXL, memory expansion becomes more flexible over the interconnect fabric while enabling coherent memory access via load/store instructions. And CXL protocol provides greater scalability, the backend of CXL interface is capable of accessing diverse memory media (DRAM, Flash etc.), thereby facilitating the construction of more expansive heterogeneous memory pools.

同时，CXL接口后端可以接入不同的存储介质，从而构建更大的异构内存池

然后谈好处，谈对CXL接口后端可以接入各种不同的设备，不需要接入同构的内存，可以用来构建更大的同构内存池。


The CXL protocol is agnostic to the underlying memory technologies, enabling seamless support for a range of media, including DRAM, Flash, and other non-volatile memories. 



Concurrently, the backend of the CXL interface is capable of accessing diverse storage media with enhanced scalability, thereby facilitating the construction of more expansive heterogeneous memory pools.



### Abstract

版本一：

This paper introduces CXL-MemSim, a pioneering full-system simulator for Compute Express Link (CXL) disaggregated memory systems, developed on the gem5 platform. Addressing the need for in-depth analysis in the absence of mature commercial CXL devices, CXL-MemSim offers a configurable model for CXL memory expansion, enabling the study of system performance under various memory parameters.

Our evaluation using Membench and Stream benchmarks reveals that CXL host-managed device memory (HDM) exhibits latency approximately 1.5 times that of DRAM, with bandwidth at 70-80% of DRAM's capacity. Application-level studies with Redis indicate that the integration of heterogeneous memory does not automatically enhance performance, highlighting the importance of strategic memory management.

CXL-MemSim's design facilitates a comprehensive understanding of CXL systems, providing a valuable tool for future research and development in next-generation memory technologies. The simulator's scalability is demonstrated through the successful integration of CXL-SSD modules, showcasing its adaptability across different memory media.



版本二（原版）：

As data volumes and computing task complexity grow, traditional systems with limited memory slots struggle to keep up. CXL, an open industry standard interconnect, offers a solution for memory disaggregation and pooling. However, building actual physical systems remains challenging as CXL memory devices are not yet commercially mature.

To efficiently and cost-effectively analyse the  disaggregated memory  system with CXL, and assess its performance using real applications, we propose CXL-MemSim, a  CXL disaggregated memory system simulator based on gem5. At the hardware level, we design and fabricate the CXL memory device with compatibility for the CXL memory protocol. Additionally, we provide a driver for the CXL device to facilitate the utilisation of memory resources by applications. With this simulator, we are able to implement additional CXL memory expansion with flexible settings for capacity, latency and other parameters.

Based on this simulator, we evaluate the performance of the CXL disaggregated memory system. We examine local DRAM's latency and bandwidth against CXL host-managed device memory (HDM) using LMbench and Stream benchmarks. In our disaggregated memory system, the latency of HDM is approximately 1.5 times that of DRAM, while HDM bandwidth ranges between 70-80\% of DRAM's capacity. We conduct an experiment on Redis, examining its performance with different memory policie, and find that simply using heterogeneous memory does not improve performance due to the higher latency and lower bandwidth of CXL HDM. 
%We also find that adding additional HDM can significantly improve system performance when local DRAM capacity is limited.



版本三（新）：

The escalating demand for enhanced memory capacity in modern heterogeneous computing systems, driven by data-intensive applications such as AI/ML and big data analytics, has highlighted the limitations of traditional memory architectures. Compute Express Link (CXL) emerges as a promising solution, offering a high-speed memory-semantic interconnect that facilitates memory disaggregation. However, the infancy of CXL technology and the absence of commodity products necessitate a robust simulation tool for research and development. 

This paper introduces CXL-MemSim, a full-system simulator to simulate CXL disaggregated memory systems with high fidelity. Built upon the gem5 simulator, CXL-MemSim incorporates a flexible CXL memory expander model, support for CXL.io and CXL.mem sub-protocols, and a comprehensive driver suite for both application-managed and kernel-managed memory allocation modes. The simulator has been rigorously verified against a real hardware prototype, demonstrating its accuracy in simulating the latency and bandwidth characteristics of CXL memory devices. CXL-MemSim not only validates the system's feasibility but also provides insights into the performance implications of heterogeneous memory policies. The findings from this work underscore the potential of CXL memory in expanding memory capacity and bandwidth for memory-intensive applications. The simulator's scalability is showcased through the integration of a CXL-SSD module, highlighting its potential for future research into heterogeneous memory-pooled systems. 

---------

参考：

This paper introduces CXL-MemSim, a sophisticated, open-source full-system simulator designed to emulate CXL disaggregated memory systems with high fidelity. Addressing the escalating demand for enhanced memory capacity in heterogeneous computing systems, particularly for data-intensive applications like AI/ML and big data analytics, CXL-MemSim leverages the gem5 simulator to provide a flexible CXL memory expander model. It supports the CXL.io and CXL.mem sub-protocols and offers a comprehensive driver suite catering to both application-managed and kernel-managed memory allocation strategies.

Rigorously verified against a real hardware prototype, CXL-MemSim accurately simulates the latency and bandwidth profiles of CXL memory devices, affirming its reliability in predicting system performance. The simulator not only validates the feasibility of CXL-based systems but also elucidates the performance benefits of heterogeneous memory policies. By demonstrating the impact of CXL memory on expanding memory capacity and bandwidth for memory-intensive applications, CXL-MemSim paves the way for future research into heterogeneous memory-pooled systems, as exemplified by the seamless integration of a CXL-SSD module.

---------

终版：

==The escalating demand for enhanced memory capacity in modern heterogeneous computing systems, driven by data-intensive applications such as AI/ML and big data analytics, has highlighted the limitations of traditional memory architectures.== Compute Express Link (CXL) emerges as a promising solution, offering a high-speed memory-semantic interconnect that facilitates memory disaggregation. However, the infancy of CXL technology and the absence of commodity products necessitate a robust simulation tool for research and development. 

This paper introduces CXL-MemSim, an open-source full-system simulator to simulate CXL disaggregated memory systems with high fidelity. Built upon the gem5 simulator, CXL-MemSim incorporates a flexible CXL memory expander model, support for CXL.io and CXL.mem sub-protocols, and a comprehensive driver suite for both application-managed and kernel-managed memory allocation modes. The simulator has been rigorously verified against a real hardware prototype, demonstrating its accuracy in simulating the latency and bandwidth characteristics of CXL memory devices. CXL-MemSim validates the system's feasibility and provides insights into the performance implications of heterogeneous memory policies. The findings from this work underscore the benefits of CXL memory in expanding memory capacity and bandwidth for memory-intensive applications. The simulator's scalability is showcased through the integration of a CXL-SSD module, highlighting its potential for future research into heterogeneous memory-pooled systems. 

-----

As data-intensive applications like AI/ML and big data analytics push the boundaries of modern heterogeneous computing systems, the need for expanded memory capacity becomes evident, revealing the constraints of conventional memory architectures. In response, Compute Express Link (CXL) stands out as an innovative solution. It introduces a high-speed, memory-semantic interconnect that effectively enables memory disaggregation, addressing these challenges by allowing for more flexible and scalable memory resource management.

------

Data-intensive applications such as AI/ML and big data analytics are stretching the capabilities of modern heterogeneous computing systems, underscoring the need for increased memory capacity and exposing the limitations of traditional memory architectures.

------

AI/ML and big data analytics are exposing the limitations of traditional memory architectures by escalating the demand for memory capacity in heterogeneous computing systems.

----------

加数据版：

Data-intensive applications such as AI/ML and big data analytics are driving up the demand for memory capacity in heterogeneous computing systems. This trend exposes the limitations of traditional memory architectures in meeting the needs of current applications. Compute Express Link (CXL) emerges as a promising solution, offering a high-speed memory-semantic interconnect that facilitates memory disaggregation. However, the infancy of CXL technology and the absence of commodity products necessitate a robust simulation tool for research and development. 

This paper introduces CXL-MemSim, an open-source full-system simulator to simulate CXL disaggregated memory systems with high fidelity. Built upon the gem5 simulator, CXL-MemSim incorporates a flexible CXL memory expander model, support for CXL.io and CXL.mem sub-protocols, and a comprehensive driver suite for both application-managed and kernel-managed memory allocation modes. 

The simulator has been rigorously verified against a real hardware prototype.  The results using LMbench and Stream benchmarks for CXL-MemSim are roughly the same as for real CXL memory, which exhibits latency approximately 2.6 times that of DRAM and bandwidth at 50-60% of DRAM. This demonstrates the accuracy of CXL-MemSim in simulating the characteristics of CXL memory devices. CXL-MemSim not only validates the system's usability but also provides insights into the performance implications of heterogeneous memory policies in real-world scenarios, such as with Redis. The study also reveals that CXL memory significantly enhances performance in memory-intensive applications, offering gains of 13-75% with limited memory and approximately a 10% improvement in bandwidth-sensitive scenarios. The simulator's scalability is showcased through the integration of a CXL-SSD module, highlighting its potential for future research into heterogeneous memory pool systems. 

-----

Furthermore, CXL-MemSim's application in real-world scenarios, such as the in-memory database Redis and the hybrid PMEM-DRAM key-value store Viper, reveals the complex interplay of heterogeneous memory policies on system throughput.

Especially, when local memory capacity is insufficient, CXL-MemSim's expansion strategies significantly enhance system throughput, as evidenced by the Redis and Viper benchmarks. The Redis performance metric, Queries Per Second (QPS), was highest when utilizing DDR-L memory and decreased with the introduction of less performant memory types. Similarly, Viper's QPS remained consistent across various memory configurations when data volume did not exceed DDR-L capacity, but dropped significantly when data size surpassed DDR-L's threshold, necessitating swap space usage.

The benefits of CXL memory for bandwidth expansion are further highlighted in memory-intensive tasks such as inference operations within Facebook's Deep Learning Recommendation Model (DLRM), where CXL-MemSim demonstrated improved performance over DDR-L in interleaved memory configurations.

Demonstrating exceptional scalability, CXL-MemSim's integration of a CXL-SSD module showed that with appropriate cache strategies, the QPS of CXL-SSD could reach 72%-88% of that of CXL-DRAM, despite the higher access latency of Flash-based storage.
